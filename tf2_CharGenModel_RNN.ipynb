{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2 로 Chracter 생성 모델을 RNN 기반으로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "from tensorflow import feature_column as fc\n",
    "import tensorflow_datasets as tfds\n",
    "plt.rcParams[\"font.family\"] = 'NanumBarunGothic'\n",
    "TENSORBOARD_BINARY = '/home/hoondori/anaconda3/envs/ai/bin/tensorboard'\n",
    "os.environ['TENSORBOARD_BINARY'] =  TENSORBOARD_BINARY\n",
    "%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'r', 'o', 'j', 'e']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"/tmp/logs/CharModel\"\n",
    "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
    "LOG_DIR = os.path.join(DATA_DIR, \"logs\")\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_logs():\n",
    "    shutil.rmtree(CHECKPOINT_DIR, ignore_errors=True)\n",
    "    shutil.rmtree(LOG_DIR, ignore_errors=True)\n",
    "\n",
    "\n",
    "def download_and_read(urls):\n",
    "    texts = []\n",
    "    for i, url in enumerate(urls):\n",
    "        p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url,\n",
    "            cache_dir=\".\")\n",
    "        text = open(p, mode=\"r\", encoding=\"utf-8\").read()\n",
    "        # remove byte order mark\n",
    "        text = text.replace(\"\\ufeff\", \"\")\n",
    "        # remove newlines\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub(r'\\s+', \" \", text)\n",
    "        # add it to the list\n",
    "        texts.extend(text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# download and read into local data structure (list of chars)\n",
    "texts = download_and_read([\n",
    "    \"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\",\n",
    "    \"https://www.gutenberg.org/files/12/12-0.txt\"\n",
    "])\n",
    "#clean_logs()\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 90\n",
      "vocab: [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "# 어휘 생성\n",
    "vocab = sorted(set(texts))\n",
    "char2idx = {c:i for i, c in enumerate(vocab)}\n",
    "idx2char = {i:c for i, c in enumerate(vocab)}\n",
    "print(\"vocab size: {:d}\".format(len(vocab)))\n",
    "print(f\"vocab: {vocab[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Char seq => Int seq => tf dataset\n",
    "text_arr = np.array([char2idx[c] for c in texts])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(text_arr)\n",
    "\n",
    "# 무한히 긴 시퀀스를 일정 크기의 배치로 변경\n",
    "#  - Inf => (None, 100)\n",
    "seq_length = 100\n",
    "dataset = dataset.batch(seq_length+1, drop_remainder=True)  # +1 은 X, y 처리를 고려\n",
    "\n",
    "# X 는 0:-1 까지, y는 1:end \n",
    "def split_train_labels(sequence):\n",
    "    input_seq = sequence[0:-1]\n",
    "    output_seq = sequence[1:]\n",
    "    return input_seq, output_seq\n",
    "\n",
    "dataset = dataset.map(split_train_labels)\n",
    "\n",
    "# 훈련 배치 설정 \n",
    "# X = (None, 64, 100), Y = (None, 64, 100)\n",
    "batch_size = 64\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"char_gen_model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     multiple                  23040     \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  multiple                  394752    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  23130     \n",
      "=================================================================\n",
      "Total params: 440,922\n",
      "Trainable params: 440,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class CharGenModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_sz, rnn_output_dim, **kwargs):\n",
    "        super(CharGenModel, self).__init__()\n",
    "    \n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=emb_sz)\n",
    "    \n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            rnn_output_dim,\n",
    "            recurrent_initializer='glorot_uniform', # default: orthogonal\n",
    "            recurrent_activation='sigmoid',  # default : tanh\n",
    "            return_sequences=True,\n",
    "            stateful=True\n",
    "        )\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.rnn(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_output_dim = embedding_dim\n",
    "\n",
    "model = CharGenModel(vocab_size, embedding_dim, rnn_output_dim)\n",
    "model.build(input_shape=(batch_size, seq_length))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 90)\n"
     ]
    }
   ],
   "source": [
    "# output shape 확인\n",
    "for input_batch, label_batch in dataset.take(1):\n",
    "    pred_batch = model(input_batch)\n",
    "    print(pred_batch.shape)\n",
    "    \n",
    "assert(pred_batch.shape[0] == batch_size)\n",
    "assert(pred_batch.shape[1] == seq_length)\n",
    "assert(pred_batch.shape[2] == vocab_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 생성기\n",
    "def generate_text(model, prefix_string, char2idx, idx2char,\n",
    "        num_chars_to_generate=1000, temperature=1.0):\n",
    "    input = [char2idx[s] for s in prefix_string]\n",
    "    input = tf.expand_dims(input, 0)\n",
    "    #print(f'prefix: {input}')\n",
    "    \n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    for i in range(num_chars_to_generate):\n",
    "        preds = model(input)\n",
    "        preds = tf.squeeze(preds, 0) / temperature    # 카테고리 분포 pdf  리턴했으므로 아래에서 sampling\n",
    "        \n",
    "        # predict char returned by model\n",
    "        pred_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\n",
    "        text_generated.append(idx2char[pred_id])\n",
    "        # pass the prediction as the next input to the model\n",
    "        input = tf.expand_dims([pred_id], 0)\n",
    "\n",
    "    return prefix_string + \"\".join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 3.3386\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.6026\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.3619\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2210\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.0995\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.9893\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.8972\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.8181\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.7371\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.6844\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1\n",
      "Alice Red Hum. And the Project Gry dever all, I'm somerenodem to creethed in she prothers, camest &m, astersaippdation? Orly pair, silo he too mest natten it?’ said SReeave On the Fromming fould agaid, but thin Dorto tem with she jainguns alled in acmish, so he’r-t ArTw such the cried as siet aftalled ap beganbler, ithat she ay, whot anything her atree! Don it!’ said the Mobe my in’t it: and she had and undinum).. Alice wed down reak it was quere to you and show is, its she cam o) consed?’ the thought, no bes--’ Mideraly,' shat in she!\" Alice, ‘and some suing that’s a head wat THaTurn ageable sonen, as a shamp a notale trages, and sheme?\" saids not. Alice had litterse dren herself.’ Hustle feat look a cridiceching and mene he had my justry prottle, whre!’ Rem Queen they doUnd himpsne tandle off in a fanding it in tho Dourlan. ANOS NIVEN PREBRY’t hat the DURE she had fight, and plead itder if ry way. The yougratice Project Guch,’ The UKLIJ * King. ‘Hays if--Will,\" said “RYADED DOD, pyoughe wa\n",
      "---\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.6333\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5878\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5485\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5141\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4876\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4597\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4290\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4125\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3829\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3725\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2\n",
      "Alice quickly courarey is ited you a wake nothing. ‘Pantarpun againd to deiplouso Alice don’t leared at beginn \"There's the left out of copyright stapped it. Elice colsies and sprences went, od been away to hoor lave invented. ‘It wasle for _noture the dight And all interructer for geeting an befons?\" said Tweedledum. CHAPTER I NOCG carning his tea, as go talking off, and began; and breamd and renering coming, and have nothing in of?’ Alice was once in turney I don't sadd Archive Foum now I should corsectronic worr, you seem within wonderformation, ready-hone the tings plance words with his her repeit a minutes; but they alwayts almouth-ground discrine you one to ter trining off. \"Come that one. ‘I’manswing at hend access? Who seels your metter,’ she said. ‘I can’t un inding-flawly: \"but with there with try odea-days of ‘OUST: We changer--and renar. ANDITER \"MY WIY LOKICT·RACMESN'N’TE REAMS A she had get up his head!’ said the one us that up to tellest to cam out of a gree facchal makiep of \n",
      "---\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 12ms/step - loss: 1.3512\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3338\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.3179\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3032\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2888\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2746\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2658\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2480\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2372\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.2260\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3\n",
      "Alice loudly (this--but she had never have do you have scroom half shawing the large was in the terms of this momenton-by it itted somewhere!\" thought she trietly Speak round; at tick of the tables stoprief failt lodit: The Caterpillar. \"As it each! How you don’t think I don’t means I know,’ cried Two,\" Said “Mich of dispeather out a rowong in a way. \"I many walked by, that they gastaid the kittens agled to the door is sich dread.) And the Project Gutenberg-tm License (callu knew it!\" and at his ranch of them was to the idea Drunched or other something losations looking back on his hurry and had flowly a good little direction Twreat little tarts queers a might nonser. ‘Well, I she had something. \"May _They mysted at all-facted: ‘but, that afreed up,’ the Four down and only ridections from the Dormouse, \"What_ haven’t come chied to herself, hands,’ All my feet, though the Lut of attermandly pretty voices being about like the empty7 The Fing with a very enderwards,\" the Knight said to have the\n",
      "---\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.2132\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2029\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1928\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1849\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1717\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1643\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1527\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1434\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1330\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1319\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4\n",
      "Alice said.’ Alice replied, as she did comser, and was in great cular that she was marked your his joint! Fach you agree to speck. Tweedledum. ‘Where when they. She fou?’ the White Rabbit before complered into the bottly! However, it seemed to startic dome, curious hervel! Alice could have d and kneeze, and Alice replied through a fell Project Gutenberg-tm about which is to stop.’ ‘Was of the end of the presently associated tears, but she birds, of alwaysclualy; but his snueze. [Illustration] \"Come, must time to the ress that they'd busy, won't mindow-\" (Alice thought the sam inches wither three word no replacements should be!\" said the Unicorn from back it it usuas.” Alice got into the last little gently up, unthing on Alice, a gfovered his note-comes tone. ‘Turn this time. Alice gat time, but he seip dressed to the true: This time the Rabbit snorming, dispette them to put the shook these to get in its means!\" she wak a paper of this pieded site and have it? you must be supposite.’ ‘It’s no\n",
      "---\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 12ms/step - loss: 1.1164\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1072\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0985\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0913\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0832\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0734\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0681\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0551\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.0515\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.0414\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5\n",
      "Alice went on expensation's quarked down!’ Alice asked \"man,’ said the Queen, but she wanted to herself, all round, And as the Mouse could nos mouth we.\" Holder of a rule to get now,’ she said, as she spoke. ‘Yes, in char; came of sightion. [Illustration] The chow bagled to pretend the shalls Te up changed the owner in a grast. ‘'st\" said Alice; \"would not think of no \"--the use of anything in her hair in fressy with a little anxiously: \"jection with alshe. I should have sighs. \"Very soundself logated when it was that likelt, before head to see the Queen creature. ‘You may come out.\" \"There were dark with one of the three could me!’ thought Alice, I’m dark over his eyes * * * * Gryphon. \"Nothing, you know.\" \"Well, then the Hatter. \"No, she’d smim-place that gleating nor, That’s the March Haices, and met?’ the Hatter, on way,’ the Looking-glass room in a Lobster.’ ‘Chale?’ said the Gryphon been only makes one garden feash! And I'll jump to yarts.,\" Uterblited at Alice with which they poor Ali\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, predictions):\n",
    "    return tf.losses.sparse_categorical_crossentropy(\n",
    "        labels,\n",
    "        predictions,\n",
    "        from_logits=True\n",
    "    )\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=loss)\n",
    "\n",
    "# we will train our model for 50 epochs, and after every 10 epochs\n",
    "# we want to see how well it will generate text\n",
    "num_epochs = 50\n",
    "steps_per_epoch = len(texts) // seq_length // batch_size\n",
    "for i in range(num_epochs // 10):\n",
    "    model.fit(\n",
    "        dataset.repeat(),\n",
    "        epochs=10,\n",
    "        steps_per_epoch=steps_per_epoch\n",
    "        # callbacks=[checkpoint_callback, tensorboard_callback]\n",
    "    )\n",
    "    checkpoint_file = os.path.join(\n",
    "        CHECKPOINT_DIR, \"model_epoch_{:d}\".format(i+1))\n",
    "    model.save_weights(checkpoint_file)\n",
    "\n",
    "    # create a generative model using the trained model so far\n",
    "    gen_model = CharGenModel(vocab_size, embedding_dim, rnn_output_dim)\n",
    "    gen_model.load_weights(checkpoint_file)\n",
    "    gen_model.build(input_shape=(1, seq_length))\n",
    "\n",
    "    print(\"after epoch: {:d}\".format(i+1)*10)\n",
    "    print(generate_text(gen_model, \"Alice \", char2idx, idx2char))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
