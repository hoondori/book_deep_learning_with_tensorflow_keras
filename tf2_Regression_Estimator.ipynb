{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "from tensorflow import feature_column as fc\n",
    "plt.rcParams[\"font.family\"] = 'NanumBarunGothic'\n",
    "TENSORBOARD_BINARY = '/home/hoondori/anaconda3/envs/ai/bin/tensorboard'\n",
    "os.environ['TENSORBOARD_BINARY'] =  TENSORBOARD_BINARY\n",
    "%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator 기반 타이타닉 문제\n",
    "\n",
    "* https://www.tensorflow.org/tutorials/estimator/linear?hl=ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 데이터셋 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((627, 9), 264)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape, dfeval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "NUM_COLS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CAT_COLS:\n",
    "    voca = dftrain[feature_name].unique()\n",
    "    feature_columns.append(fc.categorical_column_with_vocabulary_list(feature_name, voca))\n",
    "    \n",
    "for feature_name in NUM_COLS:\n",
    "    feature_columns.append(fc.numeric_column(feature_name, dtype=tf.float32))\n",
    "#feature_columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input_fn 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, shuffle=True, epochs=10, batch_size=32):\n",
    "\n",
    "    def input_fn():\n",
    "        #  \n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if( shuffle):\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(epochs)\n",
    "        return ds\n",
    "    \n",
    "    return input_fn\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
      "[b'Third' b'Second' b'First' b'Second' b'Second']\n",
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "ds = make_input_fn(dftrain, y_train, batch_size=5)()\n",
    "for f, l in ds.take(1):\n",
    "    print(list(f.keys()))\n",
    "    print(f['class'].numpy())\n",
    "    print(l.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7348485, 'accuracy_baseline': 0.625, 'auc': 0.8343128, 'auc_precision_recall': 0.79315144, 'average_loss': 0.48207965, 'label/mean': 0.375, 'loss': 0.47611183, 'precision': 0.6407767, 'prediction/mean': 0.41162443, 'recall': 0.6666667, 'global_step': 200}\n"
     ]
    }
   ],
   "source": [
    "linear_classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "linear_classifier.train(train_input_fn)\n",
    "eval_result = linear_classifier.evaluate(eval_input_fn)\n",
    "# linear_classifier.get_variable_names()\n",
    "\n",
    "clear_output()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'예측 확률'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dicts = list(linear_classifier.predict(eval_input_fn))\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "clear_output()\n",
    "probs.plot(kind='hist', bins=20, title='예측 확률')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_eval, probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('오탐률(false positive rate)')\n",
    "plt.ylabel('정탐률(true positive rate)')\n",
    "plt.xlim(0,)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator 기반 MNIST 예측기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-03T14:54:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/logs/mnist/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.12964s\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-03-14:54:17\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9248, average_loss = 0.26681885, global_step = 10000, loss = 0.2653051\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/logs/mnist/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "def estimate_mnist(log_dir):\n",
    "    \n",
    "    # load data\n",
    "    ((train_data, train_labels),(eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()    \n",
    "    train_data = train_data/np.float32(255)\n",
    "    train_labels = train_labels.astype(np.int32)  \n",
    "    eval_data = eval_data/np.float32(255)\n",
    "    eval_labels = eval_labels.astype(np.int32)    \n",
    "\n",
    "    # estimator 정의\n",
    "    classifier = tf.estimator.LinearClassifier(\n",
    "        feature_columns=[tf.feature_column.numeric_column(\"x\", shape=[28, 28])],\n",
    "        n_classes=10,\n",
    "        model_dir=log_dir\n",
    "    )\n",
    "    \n",
    "    # input fn\n",
    "    train_input_fn =  tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    \n",
    "    val_input_fn =  tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    # train\n",
    "    classifier.train(input_fn=train_input_fn, steps=10000)\n",
    "    \n",
    "    # eval\n",
    "    clear_output()\n",
    "    eval_results = classifier.evaluate(input_fn=val_input_fn)\n",
    "    #print(eval_results)\n",
    "\n",
    "!rm -rf /tmp/logs/mnist     \n",
    "estimate_mnist('/tmp/logs/mnist')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6010 (pid 51732), started 0:06:21 ago. (Use '!kill 51732' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-70bf923988dc2909\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-70bf923988dc2909\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6010;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /tmp/logs/mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator 기반 보스턴 집값 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/logs/boston/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/hoondori/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/hoondori/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /home/hoondori/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/hoondori/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/logs/boston/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 659.29407, step = 0\n",
      "INFO:tensorflow:global_step/sec: 911.478\n",
      "INFO:tensorflow:loss = 51.08558, step = 100 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1713.91\n",
      "INFO:tensorflow:loss = 43.603317, step = 200 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1722.75\n",
      "INFO:tensorflow:loss = 36.051563, step = 300 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1540.19\n",
      "INFO:tensorflow:loss = 37.46248, step = 400 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1537.28\n",
      "INFO:tensorflow:loss = 49.43663, step = 500 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1663.38\n",
      "INFO:tensorflow:loss = 38.67483, step = 600 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1672.8\n",
      "INFO:tensorflow:loss = 56.652916, step = 700 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1638.27\n",
      "INFO:tensorflow:loss = 45.9603, step = 800 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1440.87\n",
      "INFO:tensorflow:loss = 40.584305, step = 900 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1624.14\n",
      "INFO:tensorflow:loss = 49.805973, step = 1000 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1684.84\n",
      "INFO:tensorflow:loss = 52.018303, step = 1100 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1662.12\n",
      "INFO:tensorflow:loss = 26.322649, step = 1200 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1704.23\n",
      "INFO:tensorflow:loss = 59.252754, step = 1300 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1714\n",
      "INFO:tensorflow:loss = 35.284912, step = 1400 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1734.56\n",
      "INFO:tensorflow:loss = 31.122826, step = 1500 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1696.96\n",
      "INFO:tensorflow:loss = 50.980938, step = 1600 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1708.79\n",
      "INFO:tensorflow:loss = 18.101112, step = 1700 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1683.58\n",
      "INFO:tensorflow:loss = 45.138363, step = 1800 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1677.02\n",
      "INFO:tensorflow:loss = 32.672695, step = 1900 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1642.11\n",
      "INFO:tensorflow:loss = 58.0587, step = 2000 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1703.08\n",
      "INFO:tensorflow:loss = 38.969646, step = 2100 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1709.57\n",
      "INFO:tensorflow:loss = 36.23622, step = 2200 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1658.91\n",
      "INFO:tensorflow:loss = 36.94439, step = 2300 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1661.06\n",
      "INFO:tensorflow:loss = 38.36507, step = 2400 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1662.34\n",
      "INFO:tensorflow:loss = 25.982174, step = 2500 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1641.81\n",
      "INFO:tensorflow:loss = 33.829033, step = 2600 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1734.77\n",
      "INFO:tensorflow:loss = 27.44552, step = 2700 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1703.36\n",
      "INFO:tensorflow:loss = 36.32596, step = 2800 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1719.14\n",
      "INFO:tensorflow:loss = 28.344206, step = 2900 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1671.66\n",
      "INFO:tensorflow:loss = 44.158028, step = 3000 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1641.18\n",
      "INFO:tensorflow:loss = 38.559174, step = 3100 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1690.86\n",
      "INFO:tensorflow:loss = 25.86821, step = 3200 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1711.03\n",
      "INFO:tensorflow:loss = 36.31835, step = 3300 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1673.54\n",
      "INFO:tensorflow:loss = 36.780167, step = 3400 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1629.55\n",
      "INFO:tensorflow:loss = 27.511837, step = 3500 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1656.64\n",
      "INFO:tensorflow:loss = 25.880905, step = 3600 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1624.85\n",
      "INFO:tensorflow:loss = 46.731606, step = 3700 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1655.43\n",
      "INFO:tensorflow:loss = 30.163538, step = 3800 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1710.13\n",
      "INFO:tensorflow:loss = 30.345682, step = 3900 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1719.05\n",
      "INFO:tensorflow:loss = 23.07849, step = 4000 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1693.42\n",
      "INFO:tensorflow:loss = 32.590412, step = 4100 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1646.44\n",
      "INFO:tensorflow:loss = 35.35643, step = 4200 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1633.25\n",
      "INFO:tensorflow:loss = 23.770863, step = 4300 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1672.02\n",
      "INFO:tensorflow:loss = 38.104485, step = 4400 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1654.66\n",
      "INFO:tensorflow:loss = 47.6787, step = 4500 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1634.19\n",
      "INFO:tensorflow:loss = 33.427975, step = 4600 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1640.32\n",
      "INFO:tensorflow:loss = 37.37902, step = 4700 (0.061 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1667.68\n",
      "INFO:tensorflow:loss = 36.541466, step = 4800 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1681.16\n",
      "INFO:tensorflow:loss = 27.066614, step = 4900 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1680.36\n",
      "INFO:tensorflow:loss = 19.657341, step = 5000 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1742.93\n",
      "INFO:tensorflow:loss = 33.98726, step = 5100 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1683.98\n",
      "INFO:tensorflow:loss = 34.64281, step = 5200 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1696.47\n",
      "INFO:tensorflow:loss = 34.57703, step = 5300 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1711.49\n",
      "INFO:tensorflow:loss = 27.366943, step = 5400 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1699.01\n",
      "INFO:tensorflow:loss = 30.712675, step = 5500 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1718.91\n",
      "INFO:tensorflow:loss = 18.118063, step = 5600 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1687.43\n",
      "INFO:tensorflow:loss = 18.66182, step = 5700 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1629.71\n",
      "INFO:tensorflow:loss = 39.79647, step = 5800 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1647.2\n",
      "INFO:tensorflow:loss = 43.033882, step = 5900 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1674.26\n",
      "INFO:tensorflow:loss = 31.22699, step = 6000 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1754.01\n",
      "INFO:tensorflow:loss = 22.122513, step = 6100 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1727.97\n",
      "INFO:tensorflow:loss = 33.790802, step = 6200 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1718.87\n",
      "INFO:tensorflow:loss = 27.044788, step = 6300 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1721.87\n",
      "INFO:tensorflow:loss = 32.046833, step = 6400 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1679.76\n",
      "INFO:tensorflow:loss = 25.862051, step = 6500 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1725.12\n",
      "INFO:tensorflow:loss = 19.535961, step = 6600 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1701.76\n",
      "INFO:tensorflow:loss = 27.89832, step = 6700 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1699.6\n",
      "INFO:tensorflow:loss = 35.087425, step = 6800 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1707.81\n",
      "INFO:tensorflow:loss = 40.600006, step = 6900 (0.059 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7000...\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/logs/boston/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7000...\n",
      "INFO:tensorflow:Loss for final step: 41.560596.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-03T14:53:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/logs/boston/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.19587s\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-03-14:53:45\n",
      "INFO:tensorflow:Saving dict for global step 7000: average_loss = 31.623785, global_step = 7000, label/mean = 23.078432, loss = 32.851295, prediction/mean = 23.551222\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: /tmp/logs/boston/model.ckpt-7000\n",
      "{'average_loss': 31.623785, 'label/mean': 23.078432, 'loss': 32.851295, 'prediction/mean': 23.551222, 'global_step': 7000}\n"
     ]
    }
   ],
   "source": [
    "def estimate_boston_house(log_dir):\n",
    "\n",
    "    def estimator_input_fn(df_data, df_label, epochs=20, shuffle=True, batch_size=64):\n",
    "        def input_function():\n",
    "            ds = tf.data.Dataset.from_tensor_slices((dict(df_data), df_label))\n",
    "            if shuffle:\n",
    "                ds = ds.shuffle(100)\n",
    "            ds = ds.batch(batch_size).repeat(epochs)\n",
    "            return ds\n",
    "        return input_function\n",
    "\n",
    "    # data / input fn 준비\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()    \n",
    "\n",
    "    features = ['CRIM', 'ZN', 'INDUS','CHAS','NOX','RM','AGE',\n",
    "            'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "    x_train_df = pd.DataFrame(x_train, columns= features)\n",
    "    x_test_df = pd.DataFrame(x_test, columns= features)\n",
    "    y_train_df = pd.DataFrame(y_train, columns=['MEDV'])\n",
    "    y_test_df = pd.DataFrame(y_test, columns=['MEDV'])\n",
    "\n",
    "    train_input_fn = estimator_input_fn(x_train_df, y_train_df, epochs=1000)\n",
    "    val_input_fn = estimator_input_fn(x_test_df, y_test_df, epochs=1, shuffle=False)  \n",
    "    \n",
    "    # estimator 준비\n",
    "    feature_columns = []\n",
    "    for feature_name in features:\n",
    "        feature_columns.append(fc.numeric_column(feature_name, dtype=tf.float32))\n",
    "    linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir = log_dir)\n",
    "\n",
    "    # 학습/평가/예측 \n",
    "    linear_est.train(train_input_fn, steps=50000)\n",
    "    result = linear_est.evaluate(val_input_fn)\n",
    "    predict_result = linear_est.predict(val_input_fn)\n",
    "    \n",
    "    print(result)\n",
    "#     for pred,exp in zip(predict_result, y_test[:32]):\n",
    "#         print(\"Predicted Value: \", pred['predictions'][0], \"Expected: \", exp)\n",
    "\n",
    "!rm -rf /tmp/logs/boston \n",
    "estimate_boston_house('/tmp/logs/boston/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 50850), started 0:10:49 ago. (Use '!kill 50850' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c2cf9735e5d2e0bf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c2cf9735e5d2e0bf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6009;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /tmp/logs/boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
