{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "from tensorflow import feature_column as fc\n",
    "plt.rcParams[\"font.family\"] = 'NanumBarunGothic'\n",
    "TENSORBOARD_BINARY = '/home/hoondori/anaconda3/envs/ai/bin/tensorboard'\n",
    "os.environ['TENSORBOARD_BINARY'] =  TENSORBOARD_BINARY\n",
    "%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2 로 Mobilenet v2 자체 구현 및 성능 측정 \n",
    "\n",
    "* 참고 자료 \n",
    "  * https://github.com/monatis/mobilenetv2-tf2/blob/master/mobilenetv2.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenet v2 구현 \n",
    "\n",
    "*  depthwise separate conv\n",
    "  * 3x3 depth conv -> 1x1 conv\n",
    "* inverted residual block \n",
    "  * narrow => wide => narrow\n",
    "* relu6 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     10,
     22,
     43,
     51
    ]
   },
   "outputs": [],
   "source": [
    "#### Necessary Imports for Neural Net \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define ReLU6 activation\n",
    "relu6 = tf.keras.layers.ReLU(6.)\n",
    "\n",
    "\n",
    "\n",
    "# conv2d+Batch+Relu6 묶음\n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU(6.)(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "# basic bottleneck structure\n",
    "#  - 1x1 t 배로 channel 불리기 \n",
    "#  - 3x3 DepthwiseConv  (channel 수 유지)\n",
    "#  - 1x1 target_channel\n",
    "def _bottleneck(inputs, filters, kernel, t, strides, r=False):\n",
    "    \n",
    "    tchannel = inputs.shape[-1] * t\n",
    "    \n",
    "    x = _conv_block(inputs, tchannel, (1,1), (1,1))\n",
    "    \n",
    "    x = tf.keras.layers.DepthwiseConv2D(\n",
    "        kernel, strides=strides, depth_multiplier=1, padding='same')(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU(6.)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters, (1,1), strides=(1,1), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU(6.)(x)\n",
    "    \n",
    "    if r:\n",
    "        x = tf.keras.layers.add([x, inputs])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def _inverted_residual_block(inputs, filters, kernel, t, strides, n):\n",
    "    x = _bottleneck(inputs, filters, kernel, t, strides)\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, 1, True)\n",
    "\n",
    "    return x\n",
    "\n",
    "def MobileNetV2(input_shape, k):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, name='input')\n",
    "    x = _conv_block(inputs, 32, (3, 3), strides=(2, 2))\n",
    "    \n",
    "    x = _inverted_residual_block(x, 16, (3, 3), t=1, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 24, (3, 3), t=6, strides=2, n=2)\n",
    "    x = _inverted_residual_block(x, 32, (3, 3), t=6, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 64, (3, 3), t=6, strides=2, n=4)\n",
    "    x = _inverted_residual_block(x, 96, (3, 3), t=6, strides=1, n=3)\n",
    "    x = _inverted_residual_block(x, 160, (3, 3), t=6, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 320, (3, 3), t=6, strides=1, n=1)\n",
    "   \n",
    "    x = _conv_block(x, 1280, (1,1), strides=(1,1))\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Reshape((1,1,1280))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='Dropout')(x)\n",
    "    x = tf.keras.layers.Conv2D(k, (1,1), (1,1), padding='same')(x)  # target class\n",
    "    x = tf.keras.layers.Activation('softmax', name='final_activation')(x)\n",
    "    output = tf.keras.layers.Reshape((k,), name='output')(x)\n",
    "    model = tf.keras.models.Model(inputs, output)\n",
    "    #model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 2.4044 - accuracy: 0.1377 - val_loss: 2.3328 - val_accuracy: 0.1025\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 2.1090 - accuracy: 0.2326 - val_loss: 2.1169 - val_accuracy: 0.1930\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.8510 - accuracy: 0.3100 - val_loss: 2.7155 - val_accuracy: 0.2545\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.6652 - accuracy: 0.3883 - val_loss: 2.4511 - val_accuracy: 0.2413\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.5039 - accuracy: 0.4543 - val_loss: 1.8716 - val_accuracy: 0.3992\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.4069 - accuracy: 0.4979 - val_loss: 1.8296 - val_accuracy: 0.4402\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.3589 - accuracy: 0.5244 - val_loss: 1.4752 - val_accuracy: 0.4769\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.2745 - accuracy: 0.5468 - val_loss: 1.6867 - val_accuracy: 0.4295\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.1922 - accuracy: 0.5760 - val_loss: 1.4702 - val_accuracy: 0.4986\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.1535 - accuracy: 0.5956 - val_loss: 1.4752 - val_accuracy: 0.5300\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.0956 - accuracy: 0.6147 - val_loss: 1.6347 - val_accuracy: 0.4956\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.0551 - accuracy: 0.6307 - val_loss: 1.2649 - val_accuracy: 0.5748\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.0228 - accuracy: 0.6436 - val_loss: 1.3273 - val_accuracy: 0.5583\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.9714 - accuracy: 0.6575 - val_loss: 1.5335 - val_accuracy: 0.5431\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.9803 - accuracy: 0.6691 - val_loss: 1.3402 - val_accuracy: 0.5660\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.9064 - accuracy: 0.6819 - val_loss: 1.2882 - val_accuracy: 0.5989\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.8599 - accuracy: 0.6977 - val_loss: 1.1421 - val_accuracy: 0.6050\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.8475 - accuracy: 0.7033 - val_loss: 1.3324 - val_accuracy: 0.5865\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.8023 - accuracy: 0.7178 - val_loss: 1.1368 - val_accuracy: 0.6216\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.7656 - accuracy: 0.7292 - val_loss: 1.3075 - val_accuracy: 0.6017\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.3114 - accuracy: 0.5951\n",
      "\n",
      "Test score: 1.3114092350006104\n",
      "Test accuracy: 0.5950999855995178\n"
     ]
    }
   ],
   "source": [
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "log_dir = '/tmp/logs/mobilenetv2'\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "# normalize\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "# convert to categorical\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, CLASSES)\n",
    "\n",
    "model = MobileNetV2(input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS), k=CLASSES)\n",
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# use TensorBoard\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "]\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS, validation_split=VALIDATION_SPLIT, \n",
    "    verbose=VERBOSE, callbacks=callbacks) \n",
    "score = model.evaluate(X_test, y_test,\n",
    "                     batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
