{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2 로 seq2seq 구현  (with attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU[0] is ready\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print('GPU[0] is ready')\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "        print(e)\n",
    "else:\n",
    "    print('Please check GPU available')\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "from tensorflow import feature_column as fc\n",
    "import tensorflow_datasets as tfds\n",
    "plt.rcParams[\"font.family\"] = 'NanumBarunGothic'\n",
    "TENSORBOARD_BINARY = '/home/hoondori/anaconda3/envs/ai/bin/tensorboard'\n",
    "os.environ['TENSORBOARD_BINARY'] =  TENSORBOARD_BINARY   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import unicodedata\n",
    "import zipfile\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 처리\n",
    "\n",
    "* teacher forcing을 사용해야 하므로 (X, Y, Y') 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    sent = \"\".join([c for c in unicodedata.normalize(\"NFD\", sent) \n",
    "        if unicodedata.category(c) != \"Mn\"])\n",
    "    sent = re.sub(r\"([!.?])\", r\" \\1\", sent)\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    sent = sent.lower()\n",
    "    return sent\n",
    "\n",
    "\n",
    "def download_and_read():\n",
    "    en_sents, fr_sents_in, fr_sents_out = [], [], []\n",
    "    local_file = '/home/hoondori/data/fra-eng/fra.txt'\n",
    "    with open(local_file, \"r\") as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            en_sent, fr_sent, _ = line.strip().split('\\t')\n",
    "            en_sent = [w for w in preprocess_sentence(en_sent).split()]\n",
    "            fr_sent = preprocess_sentence(fr_sent)\n",
    "            fr_sent_in = [w for w in (\"BOS \" + fr_sent).split()]\n",
    "            fr_sent_out = [w for w in (fr_sent + \" EOS\").split()]\n",
    "            en_sents.append(en_sent)\n",
    "            fr_sents_in.append(fr_sent_in)\n",
    "            fr_sents_out.append(fr_sent_out)\n",
    "            if i >= NUM_SENT_PAIRS - 1:\n",
    "                break\n",
    "    return en_sents, fr_sents_in, fr_sents_out\n",
    "\n",
    "NUM_SENT_PAIRS = 30000\n",
    "sents_en, sents_fr_in, sents_fr_out = download_and_read()\n",
    "print(len(sents_en), len(sents_fr_in), len(sents_fr_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size (en): 4339, vocab size (fr): 7649\n",
      "seqlen (en): 8, (fr): 16\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en)\n",
    "data_en = tokenizer_en.texts_to_sequences(sents_en)\n",
    "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en, padding=\"post\")\n",
    "\n",
    "tokenizer_fr = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters=\"\", lower=False)\n",
    "tokenizer_fr.fit_on_texts(sents_fr_in)\n",
    "tokenizer_fr.fit_on_texts(sents_fr_out)\n",
    "data_fr_in = tokenizer_fr.texts_to_sequences(sents_fr_in)\n",
    "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in, padding=\"post\")\n",
    "data_fr_out = tokenizer_fr.texts_to_sequences(sents_fr_out)\n",
    "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out, padding=\"post\")\n",
    "\n",
    "vocab_size_en = len(tokenizer_en.word_index)\n",
    "vocab_size_fr = len(tokenizer_fr.word_index)\n",
    "word2idx_en = tokenizer_en.word_index\n",
    "idx2word_en = {v:k for k, v in word2idx_en.items()}\n",
    "word2idx_fr = tokenizer_fr.word_index\n",
    "idx2word_fr = {v:k for k, v in word2idx_fr.items()}\n",
    "print(\"vocab size (en): {:d}, vocab size (fr): {:d}\".format(\n",
    "    vocab_size_en, vocab_size_fr))\n",
    "\n",
    "maxlen_en = data_en.shape[1]\n",
    "maxlen_fr = data_fr_out.shape[1]\n",
    "print(\"seqlen (en): {:d}, (fr): {:d}\".format(maxlen_en, maxlen_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 8), (128, 16), (128, 16)), types: (tf.int32, tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "BATCH_SIZE = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_en, data_fr_in, data_fr_out))\n",
    "dataset = dataset.shuffle(10000)\n",
    "test_size = NUM_SENT_PAIRS // 4\n",
    "test_dataset = dataset.take(test_size).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = dataset.skip(test_size).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_timesteps, encoder_dim, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embedding_dim, input_length=num_timesteps)\n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            encoder_dim, return_sequences=True, return_state=True)   # attention 사용을 위해 return_sequences=True\n",
    "\n",
    "    def call(self, x, state):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.rnn(x, initial_state=state)\n",
    "        return x, state\n",
    "\n",
    "    def init_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.encoder_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bahdanau Attention : e = v_t tanh(W[query; value])  \n",
    "\n",
    "* query는 디코더 은닉 상태, value는 인코더 은닉 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_units, **kwargs):\n",
    "        super(BahdanauAttention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.Wq = tf.keras.layers.Dense(num_units) \n",
    "        self.Wv = tf.keras.layers.Dense(num_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        \n",
    "        # query shape : (batch_size, num_units)\n",
    "        # value shape : (batch_size, timesteps, num_units)\n",
    "        \n",
    "        # (batch_size, 1, num_units)\n",
    "        query_with_time_axis = tf.expand_dims(query, axis=1)  \n",
    "        \n",
    "        # (batch_size, timesteps, 1)\n",
    "        scores = self.V( tf.keras.activations.tanh(             \n",
    "            self.Wv(values) + self.Wq(query_with_time_axis)\n",
    "        ))\n",
    "        \n",
    "        # (batch_size, timesteps, 1)\n",
    "        alignments = tf.nn.softmax(scores, axis=1)  \n",
    "        \n",
    "        # (batch_size, num_units)\n",
    "        context = tf.reduce_sum(\n",
    "            tf.linalg.matmul(                           # (batch_size, 1, num_units)\n",
    "                tf.linalg.matrix_transpose(alignments),   # (batch_size, 1, timesteps)\n",
    "                values                                # (batch_size, timesteps, num_units)\n",
    "            ), axis=1\n",
    "        )\n",
    "        \n",
    "        #context = tf.expand_dims(context, axis=1)   ??\n",
    "        return context, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_units):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.W = tf.keras.layers.Dense(num_units)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        \n",
    "        # query shape : (batch_size, num_units)\n",
    "        # value shape : (batch_size, timesteps, num_units)\n",
    "        \n",
    "        # (batch_size, 1, num_units)\n",
    "        query_with_time_axis = tf.expand_dims(query, axis=1)  \n",
    "        \n",
    "        # (batch_size, 1, timesteps) = (batch_size, 1, num_units) * (batch_size, num_units, timesteps) \n",
    "        scores = tf.linalg.matmul(query_with_time_axis, self.W(values), transpose_b=True)\n",
    "        \n",
    "        # (batch_size, 1, timesteps)\n",
    "        alignments = tf.nn.softmax(scores, axis=2)\n",
    "        \n",
    "        # (batch_size, num_units)\n",
    "        context = tf.reduce_sum(\n",
    "            tf.linalg.matmul(\n",
    "                alignments, \n",
    "                values\n",
    "            ), axis=1\n",
    "        )\n",
    "        \n",
    "        return context, alignments\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bahdanau: context.shape: (64, 256) alignments.shape: (64, 8, 1)\n",
      "Luong: context.shape: (64, 256) alignments.shape: (64, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_timesteps = maxlen_en\n",
    "num_units = 256\n",
    "\n",
    "query = np.random.random(size=(batch_size, num_units)).astype(np.float32)\n",
    "values = np.random.random(size=(batch_size, num_timesteps, num_units)).astype(np.float32)\n",
    "\n",
    "b_attn = BahdanauAttention(num_units)\n",
    "context, alignments = b_attn(query, values)\n",
    "print(\"Bahdanau: context.shape:\", context.shape, \"alignments.shape:\", alignments.shape)\n",
    "# # Bahdanau: context.shape: (64, 1024) alignments.shape: (64, 8, 1)\n",
    "\n",
    "l_attn = LuongAttention(num_units)\n",
    "context, alignments = l_attn(query, values)\n",
    "print(\"Luong: context.shape:\", context.shape, \"alignments.shape:\", alignments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_timesteps,decoder_dim, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        \n",
    "        self.decoder_dim = decoder_dim\n",
    "        \n",
    "        self.attention = LuongAttention(decoder_dim)\n",
    "        # self.attention = BahdanauAttention(decoder_dim)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embedding_dim, input_length=num_timesteps)\n",
    "        \n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            decoder_dim, return_sequences=True, return_state=True)\n",
    "        \n",
    "        self.Wc = tf.keras.layers.Dense(decoder_dim, activation='tanh')\n",
    "        self.Ws = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, state, encoder_out):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        context, alignments = self.attention(state, encoder_out)\n",
    "        \n",
    "        concat = tf.concat([x, context], axis=1)    # (batch_size, decoder_dim + embed_dim)\n",
    "        \n",
    "        x, state = self.rnn(\n",
    "            tf.expand_dims(concat, axis=1)\n",
    "        )\n",
    "        x = self.Wc(x)\n",
    "        x = self.Ws(x)\n",
    "        return x, state, alignments\n",
    "    \n",
    "EMBEDDING_DIM = 256\n",
    "ENCODER_DIM, DECODER_DIM = 1024, 1024\n",
    "\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "encoder_dim, decoder_dim = ENCODER_DIM, DECODER_DIM\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = Encoder(vocab_size_en+1, embedding_dim, maxlen_en, encoder_dim)\n",
    "decoder = Decoder(vocab_size_fr+1, embedding_dim, maxlen_fr, decoder_dim)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input : (128, 8)\n",
      "encoder state : (128, 1024)\n",
      "decoder input : (128, 16)\n",
      "decoder input at t: (128,)\n",
      "decoder state at t: (128, 1024)\n",
      "decoder predict at t: (128, 1, 7650)\n"
     ]
    }
   ],
   "source": [
    "# 디버깅 (출력 점검)\n",
    "\n",
    "for enc_in, dec_in, dec_out in train_dataset.take(1):\n",
    "    enc_init_state = encoder.init_state(BATCH_SIZE)\n",
    "    encoder_out,enc_state = encoder(enc_in, enc_init_state)\n",
    "    decoder_state = enc_state\n",
    "\n",
    "    print(\"encoder input :\", enc_in.shape)   # (batch_size, maxlen_en)\n",
    "    print(\"encoder state :\", enc_state.shape) # (batch_size, encdoer_dim)\n",
    "    print(\"decoder input :\", dec_in.shape) # (batch_size, maxlen_fr)\n",
    "    \n",
    "    for t in range(dec_out.shape[1]):\n",
    "        decoder_in_t = dec_in[:, t]\n",
    "        decoder_pred_t, decoder_state, _ = decoder(decoder_in_t, decoder_state, encoder_out)\n",
    "        if t == 0:\n",
    "            print(\"decoder input at t:\", decoder_in_t.shape) # (batch_size, )\n",
    "            print(\"decoder state at t:\", decoder_state.shape) # (batch_size, decoder_dim)\n",
    "            print(\"decoder predict at t:\", decoder_pred_t.shape) # (batch_size, 1, vocab_size_fr+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     27
    ]
   },
   "outputs": [],
   "source": [
    "def predict(encoder, decoder, batch_size, sents_en, data_en, sents_fr_out, word2idx_fr, idx2word_fr):\n",
    "    random_id = np.random.choice(len(sents_en))\n",
    "    print(\"input    : \",  \" \".join(sents_en[random_id]))\n",
    "    print(\"label    : \", \" \".join(sents_fr_out[random_id]))\n",
    "\n",
    "    encoder_in = tf.expand_dims(data_en[random_id], axis=0)\n",
    "    decoder_out = tf.expand_dims(sents_fr_out[random_id], axis=0)\n",
    "\n",
    "    encoder_state = encoder.init_state(1)\n",
    "    encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
    "    decoder_state = encoder_state\n",
    "\n",
    "    pred_sent_fr = []\n",
    "    decoder_in = tf.expand_dims(tf.constant(word2idx_fr[\"BOS\"]), axis=0)\n",
    "\n",
    "    while True:\n",
    "        decoder_pred, decoder_state, _ = decoder(decoder_in, decoder_state, encoder_out)\n",
    "        decoder_pred = tf.argmax(decoder_pred, axis=-1)\n",
    "        pred_word = idx2word_fr[decoder_pred.numpy()[0][0]]\n",
    "        pred_sent_fr.append(pred_word)\n",
    "        if pred_word == \"EOS\" or len(pred_sent_fr) >= maxlen_fr:\n",
    "            break\n",
    "        decoder_in = tf.squeeze(decoder_pred, axis=1)\n",
    "\n",
    "    print(\"predicted: \", \" \".join(pred_sent_fr))\n",
    "\n",
    "\n",
    "def evaluate_bleu_score(encoder, decoder, test_dataset, \n",
    "        word2idx_fr, idx2word_fr):\n",
    "\n",
    "    bleu_scores = []\n",
    "    smooth_fn = SmoothingFunction()\n",
    "\n",
    "    for encoder_in, decoder_in, decoder_out in test_dataset:\n",
    "        encoder_state = encoder.init_state(batch_size)\n",
    "        encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
    "        decoder_state = encoder_state\n",
    "\n",
    "        ref_sent_ids = np.zeros_like(decoder_out)\n",
    "        hyp_sent_ids = np.zeros_like(decoder_out)\n",
    "        for t in range(decoder_out.shape[1]):\n",
    "            decoder_out_t = decoder_out[:, t]\n",
    "            decoder_in_t = decoder_in[:, t]\n",
    "            decoder_pred_t, decoder_state, _ = decoder(\n",
    "                decoder_in_t, decoder_state, encoder_out)\n",
    "            decoder_pred_t = tf.argmax(decoder_pred_t, axis=-1)\n",
    "            for b in range(decoder_pred_t.shape[0]):\n",
    "                ref_sent_ids[b, t] = decoder_out_t.numpy()[0]\n",
    "                hyp_sent_ids[b, t] = decoder_pred_t.numpy()[0][0]\n",
    "        \n",
    "        for b in range(ref_sent_ids.shape[0]):\n",
    "            ref_sent = [idx2word_fr[i] for i in ref_sent_ids[b] if i > 0]\n",
    "            hyp_sent = [idx2word_fr[i] for i in hyp_sent_ids[b] if i > 0]\n",
    "            # remove trailing EOS\n",
    "            ref_sent = ref_sent[0:-1]\n",
    "            hyp_sent = hyp_sent[0:-1]\n",
    "            bleu_score = sentence_bleu([ref_sent], hyp_sent,\n",
    "                smoothing_function=smooth_fn.method1)\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "    return np.mean(np.array(bleu_scores))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 정의 : 둘 다 zero(PAD)인 것은 제외하고 평가\n",
    "\n",
    "def loss_fn(ytrue, ypred):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(ytrue, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = scce(ytrue, ypred, sample_weight=mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(encoder_in, decoder_in, decoder_out, encoder_state):\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
    "        decoder_state = encoder_state\n",
    "\n",
    "        loss = 0\n",
    "        for t in range(decoder_out.shape[1]):\n",
    "            decoder_in_t = decoder_in[:, t]\n",
    "            decoder_pred_t, decoder_state, _ = decoder(decoder_in_t,\n",
    "                decoder_state, encoder_out)\n",
    "            loss += loss_fn(decoder_out[:, t], decoder_pred_t)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss / decoder_out.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '/tmp/logs/seq2seq_with_attn/'\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "num_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.4314\n",
      "input    :  he gave up hope .\n",
      "label    :  il abandonna tout espoir . EOS\n",
      "predicted:  il est un chemin . EOS\n",
      "Eval Score (BLEU): 1.773e-02\n",
      "Epoch: 2, Loss: 1.1245\n",
      "input    :  i wanted more .\n",
      "label    :  j en voulais plus . EOS\n",
      "predicted:  je suis de l air . EOS\n",
      "Eval Score (BLEU): 2.523e-02\n",
      "Epoch: 3, Loss: 0.8434\n",
      "input    :  we re worried .\n",
      "label    :  nous nous faisons du souci . EOS\n",
      "predicted:  nous sommes allees . EOS\n",
      "Eval Score (BLEU): 3.435e-02\n",
      "Epoch: 4, Loss: 0.7225\n",
      "input    :  take command .\n",
      "label    :  prenez le controle . EOS\n",
      "predicted:  prenez la tete . EOS\n",
      "Eval Score (BLEU): 4.168e-02\n",
      "Epoch: 5, Loss: 0.6033\n",
      "input    :  tom grinned .\n",
      "label    :  tom souriait . EOS\n",
      "predicted:  tom chatouillait . EOS\n",
      "Eval Score (BLEU): 6.306e-02\n",
      "Epoch: 6, Loss: 0.5205\n",
      "input    :  i m desperate .\n",
      "label    :  je suis desespere . EOS\n",
      "predicted:  je suis desarme . EOS\n",
      "Eval Score (BLEU): 8.144e-02\n",
      "Epoch: 7, Loss: 0.4065\n",
      "input    :  you re early .\n",
      "label    :  vous etes en avance . EOS\n",
      "predicted:  tu es en avance . EOS\n",
      "Eval Score (BLEU): 8.558e-02\n",
      "Epoch: 8, Loss: 0.3467\n",
      "input    :  let s celebrate .\n",
      "label    :  celebrons . EOS\n",
      "predicted:  enquetons . EOS\n",
      "Eval Score (BLEU): 8.722e-02\n",
      "Epoch: 9, Loss: 0.3051\n",
      "input    :  i was burned .\n",
      "label    :  j ai ete brulee . EOS\n",
      "predicted:  j ai ete brule . EOS\n",
      "Eval Score (BLEU): 8.401e-02\n",
      "Epoch: 10, Loss: 0.3008\n",
      "input    :  who s after you ?\n",
      "label    :  qui est a tes trousses ? EOS\n",
      "predicted:  qui est apres toi ? EOS\n",
      "Eval Score (BLEU): 1.027e-01\n",
      "Epoch: 11, Loss: 0.2800\n",
      "input    :  we re divorced .\n",
      "label    :  nous sommes divorces . EOS\n",
      "predicted:  nous sommes divorces . EOS\n",
      "Eval Score (BLEU): 1.227e-01\n",
      "Epoch: 12, Loss: 0.2472\n",
      "input    :  i love this store .\n",
      "label    :  je raffole de ce magasin . EOS\n",
      "predicted:  j adore ce magasin . EOS\n",
      "Eval Score (BLEU): 1.077e-01\n",
      "Epoch: 13, Loss: 0.2281\n",
      "input    :  i want a lot .\n",
      "label    :  j en veux beaucoup . EOS\n",
      "predicted:  je veux beaucoup . EOS\n",
      "Eval Score (BLEU): 1.260e-01\n",
      "Epoch: 14, Loss: 0.2058\n",
      "input    :  we all know .\n",
      "label    :  nous le savons tous . EOS\n",
      "predicted:  nous savons toutes . EOS\n",
      "Eval Score (BLEU): 9.800e-02\n",
      "Epoch: 15, Loss: 0.2508\n",
      "input    :  i didn t look .\n",
      "label    :  je n ai pas regarde . EOS\n",
      "predicted:  je n ai pas regarde . EOS\n",
      "Eval Score (BLEU): 1.270e-01\n",
      "Epoch: 16, Loss: 0.2120\n",
      "input    :  listen closely .\n",
      "label    :  ecoute moi bien ! EOS\n",
      "predicted:  ecoute attentivement ! EOS\n",
      "Eval Score (BLEU): 1.179e-01\n",
      "Epoch: 17, Loss: 0.1727\n",
      "input    :  she seems happy .\n",
      "label    :  elle parait heureuse . EOS\n",
      "predicted:  elle a l air heureuse . EOS\n",
      "Eval Score (BLEU): 1.208e-01\n",
      "Epoch: 18, Loss: 0.1778\n",
      "input    :  my house is tiny .\n",
      "label    :  ma maison est toute petite . EOS\n",
      "predicted:  ma maison est toute petite . EOS\n",
      "Eval Score (BLEU): 1.245e-01\n",
      "Epoch: 19, Loss: 0.1991\n",
      "input    :  tom is teasing .\n",
      "label    :  tom est taquin . EOS\n",
      "predicted:  tom est taquin . EOS\n",
      "Eval Score (BLEU): 1.313e-01\n",
      "Epoch: 20, Loss: 0.1726\n",
      "input    :  this is very good .\n",
      "label    :  c est tres bien . EOS\n",
      "predicted:  c est tres bon . EOS\n",
      "Eval Score (BLEU): 1.323e-01\n",
      "Epoch: 21, Loss: 0.1597\n",
      "input    :  you re crafty .\n",
      "label    :  tu es astucieuse . EOS\n",
      "predicted:  vous etes ruse . EOS\n",
      "Eval Score (BLEU): 1.483e-01\n",
      "Epoch: 22, Loss: 0.1405\n",
      "input    :  i m a bookkeeper .\n",
      "label    :  je suis comptable . EOS\n",
      "predicted:  je suis comptable . EOS\n",
      "Eval Score (BLEU): 1.117e-01\n",
      "Epoch: 23, Loss: 0.1411\n",
      "input    :  thanks for the tea .\n",
      "label    :  merci pour le the . EOS\n",
      "predicted:  merci pour le the . EOS\n",
      "Eval Score (BLEU): 1.398e-01\n",
      "Epoch: 24, Loss: 0.1428\n",
      "input    :  nobody can stop it .\n",
      "label    :  personne ne peut y mettre un terme . EOS\n",
      "predicted:  personne ne peut y mettre un terme . EOS\n",
      "Eval Score (BLEU): 1.483e-01\n",
      "Epoch: 25, Loss: 0.1631\n",
      "input    :  tom is friendly .\n",
      "label    :  tom est aimable . EOS\n",
      "predicted:  tom est aimable . EOS\n",
      "Eval Score (BLEU): 1.158e-01\n",
      "Epoch: 26, Loss: 0.1500\n",
      "input    :  we re smart .\n",
      "label    :  nous sommes intelligentes . EOS\n",
      "predicted:  nous sommes intelligentes . EOS\n",
      "Eval Score (BLEU): 1.354e-01\n",
      "Epoch: 27, Loss: 0.1333\n",
      "input    :  that s the limit .\n",
      "label    :  c est la limite . EOS\n",
      "predicted:  c est la limite . EOS\n",
      "Eval Score (BLEU): 1.095e-01\n",
      "Epoch: 28, Loss: 0.1368\n",
      "input    :  you re psyched .\n",
      "label    :  t es remontee . EOS\n",
      "predicted:  t es remonte . EOS\n",
      "Eval Score (BLEU): 1.508e-01\n",
      "Epoch: 29, Loss: 0.1531\n",
      "input    :  who s at home ?\n",
      "label    :  il y a qui a la maison ? EOS\n",
      "predicted:  qui est a la maison ? EOS\n",
      "Eval Score (BLEU): 1.307e-01\n",
      "Epoch: 30, Loss: 0.1352\n",
      "input    :  we saw everything .\n",
      "label    :  nous avons tout vu . EOS\n",
      "predicted:  nous avons tout vu . EOS\n",
      "Eval Score (BLEU): 1.482e-01\n",
      "Epoch: 31, Loss: 0.1439\n",
      "input    :  i really am sorry .\n",
      "label    :  je suis vraiment desolee . EOS\n",
      "predicted:  je suis vraiment desole . EOS\n",
      "Eval Score (BLEU): 1.419e-01\n",
      "Epoch: 32, Loss: 0.1324\n",
      "input    :  you re confused .\n",
      "label    :  tu t embrouilles . EOS\n",
      "predicted:  vous etes confus . EOS\n",
      "Eval Score (BLEU): 1.323e-01\n",
      "Epoch: 33, Loss: 0.1518\n",
      "input    :  that s why tom won .\n",
      "label    :  c est pourquoi tom a gagne . EOS\n",
      "predicted:  c est pour ca que tom a gagne . EOS\n",
      "Eval Score (BLEU): 1.594e-01\n",
      "Epoch: 34, Loss: 0.1369\n",
      "input    :  i went twice .\n",
      "label    :  je m y suis rendue a deux reprises . EOS\n",
      "predicted:  j y suis allee deux fois . EOS\n",
      "Eval Score (BLEU): 1.479e-01\n",
      "Epoch: 35, Loss: 0.1501\n",
      "input    :  lie low .\n",
      "label    :  a terre ! EOS\n",
      "predicted:  a terre ! EOS\n",
      "Eval Score (BLEU): 1.323e-01\n",
      "Epoch: 36, Loss: 0.1357\n",
      "input    :  tom retaliated .\n",
      "label    :  tom a riposte . EOS\n",
      "predicted:  tom a riposte . EOS\n",
      "Eval Score (BLEU): 1.299e-01\n",
      "Epoch: 37, Loss: 0.1806\n",
      "input    :  i smell bacon .\n",
      "label    :  il doit y avoir des poulets dans le coin . EOS\n",
      "predicted:  il doit y avoir des poulets dans le coin . EOS\n",
      "Eval Score (BLEU): 1.458e-01\n",
      "Epoch: 38, Loss: 0.1252\n",
      "input    :  are you winning ?\n",
      "label    :  tu gagnes ? EOS\n",
      "predicted:  est ce que vous etes en train de gagner ? EOS\n",
      "Eval Score (BLEU): 1.430e-01\n",
      "Epoch: 39, Loss: 0.1182\n",
      "input    :  i felt great .\n",
      "label    :  je me suis tres bien sentie . EOS\n",
      "predicted:  je me suis tres bien senti . EOS\n",
      "Eval Score (BLEU): 1.353e-01\n",
      "Epoch: 40, Loss: 0.1337\n",
      "input    :  it sounds easy .\n",
      "label    :  ca semble aise . EOS\n",
      "predicted:  ca semble facile . EOS\n",
      "Eval Score (BLEU): 1.350e-01\n",
      "Epoch: 41, Loss: 0.1098\n",
      "input    :  be careful !\n",
      "label    :  soyez prudentes ! EOS\n",
      "predicted:  sois prudent ! EOS\n",
      "Eval Score (BLEU): 1.490e-01\n",
      "Epoch: 42, Loss: 0.1404\n",
      "input    :  this is theirs .\n",
      "label    :  ce sont les leurs . EOS\n",
      "predicted:  ce sont les leurs . EOS\n",
      "Eval Score (BLEU): 1.555e-01\n",
      "Epoch: 43, Loss: 0.1347\n",
      "input    :  what s the plan ?\n",
      "label    :  quel est le plan ? EOS\n",
      "predicted:  comment est le plan ? EOS\n",
      "Eval Score (BLEU): 1.584e-01\n",
      "Epoch: 44, Loss: 0.1209\n",
      "input    :  she didn t reply .\n",
      "label    :  elle ne repondit pas . EOS\n",
      "predicted:  elle ne repondit pas . EOS\n",
      "Eval Score (BLEU): 1.520e-01\n",
      "Epoch: 45, Loss: 0.1094\n",
      "input    :  did you phone me ?\n",
      "label    :  est ce vous qui m avez appelee ? EOS\n",
      "predicted:  est ce vous qui m avez appelee ? EOS\n",
      "Eval Score (BLEU): 1.336e-01\n",
      "Epoch: 46, Loss: 0.1022\n",
      "input    :  come back home .\n",
      "label    :  rentre a la maison . EOS\n",
      "predicted:  reviens a la maison . EOS\n",
      "Eval Score (BLEU): 1.413e-01\n",
      "Epoch: 47, Loss: 0.1025\n",
      "input    :  i was very tired .\n",
      "label    :  j etais fourbu . EOS\n",
      "predicted:  j etais tres fatiguee . EOS\n",
      "Eval Score (BLEU): 1.552e-01\n",
      "Epoch: 48, Loss: 0.0938\n",
      "input    :  tom is real cute .\n",
      "label    :  tom est vraiment craquant . EOS\n",
      "predicted:  tom est vraiment craquant . EOS\n",
      "Eval Score (BLEU): 1.367e-01\n",
      "Epoch: 49, Loss: 0.1286\n",
      "input    :  i cut myself .\n",
      "label    :  je me coupai . EOS\n",
      "predicted:  je me coupai . EOS\n",
      "Eval Score (BLEU): 1.510e-01\n",
      "Epoch: 50, Loss: 0.1138\n",
      "input    :  i don t mind .\n",
      "label    :  cela m est egal . EOS\n",
      "predicted:  cela m est egal . EOS\n",
      "Eval Score (BLEU): 1.215e-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/logs/seq2seq_with_attn/ckpt-6'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores = []\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    encoder_state = encoder.init_state(batch_size)\n",
    "\n",
    "    for i, data in enumerate(train_dataset):\n",
    "        encoder_in, decoder_in, decoder_out = data\n",
    "        # print(encoder_in.shape, decoder_in.shape, decoder_out.shape)\n",
    "        loss = train_step(\n",
    "            encoder_in, decoder_in, decoder_out, encoder_state)\n",
    "        \n",
    "        #print('{:d}/{:d} loss={:.4f}'.format(i, e, loss))\n",
    "    \n",
    "    print(\"Epoch: {}, Loss: {:.4f}\".format(e + 1, loss.numpy()))\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "    predict(encoder, decoder, batch_size, sents_en, data_en,\n",
    "        sents_fr_out, word2idx_fr, idx2word_fr)\n",
    "\n",
    "    eval_score = evaluate_bleu_score(encoder, decoder, test_dataset, word2idx_fr, idx2word_fr)\n",
    "    print(\"Eval Score (BLEU): {:.3e}\".format(eval_score))\n",
    "    # eval_scores.append(eval_score)\n",
    "\n",
    "checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
